{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Logistic Regression using Gradient Descent Algorithm\n",
    "\n",
    "We will implement logistic regression on binary classification. We will use only Gradient Descent Algorithm to minimize the cost function as discussed in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run this code cell using shift+enter before moving further\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import linear_model, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your code in place of None. Run this cell after writing your code. \n",
    "# Use Data_Cortex_Nuclear.csv file.\n",
    "df=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data has missing values. The site:\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/missing_data.html\n",
    "\n",
    "has an excellent summary of methods to deal with missing values. Following the techniques there, create a new data frame df1 where the missing values in each column are filled with the mean values from the non-missing values. Use df.fillna(df.mean())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will predict the binary class label in df1['Genotype'] which indicates if the mouse has Down's syndrome or not. Get the string values in df1['Genotype'].values and convert this to a numeric vector y with 0 or 1. You may wish to use the np.unique command with the return_inverse=True option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yraw=None\n",
    "a,y=None\n",
    "y=y.reshape((y.shape[0],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As predictors, get all but the last four columns of the dataframes i.e. values in these  'H3AcK18_N','EGR1_N','H3MeK4_N','CaNA_N' 4 columns . Standardize the data matrix and call the standardized matrix Xs. The predictors are the expression levels of the 77 genes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xnames =['H3AcK18_N','EGR1_N','H3MeK4_N','CaNA_N'] \n",
    "Xs=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize Xs using preprocessing.scale(Xs) and save in the Xs variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xs=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving further, you should know that you would be using vectorization as done in the lecture. Calculate the total number of training examples in the variable m using y.shape[0] command. Also, append a column of ones of dimension(m,1) as the first column of Xs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m=None\n",
    "# Create an array of ones of shape(m,1)\n",
    "a=None\n",
    "# Append a to left of Xs\n",
    "Xs=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid Function\n",
    "This function takes input as vector and outputs sigmoid of every element of that vector. Here v is vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "def sigmoid(v):\n",
    "    a=np.exp(-v)\n",
    "    b=1+a\n",
    "    yhat=1/b\n",
    "    \n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Function\n",
    "\n",
    "Compute the cost: Write the code to compute the cost inside the function. Do not change the function name or function parameters. Here, beta is vector having (nx+1) parameters i.e. from beta0 to beta_n where nx is the number of features or independent variable as discussed in the lecture. In this assignment, beta will be a vector of size 5 i.e. 4+1. Beta will be a column vector of dimension (nx+1,1). Use the cost function as discussed in the class. You can use the above sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(Xs,y,beta,m):\n",
    "    #Write your code in place of None. Cost can be calculated using a single line of code.\n",
    "    # First write code to calculate yhat i.e. sigmoid of dot of Xs, beta\n",
    "    yhat= None\n",
    "   \n",
    "    cost= None\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving ahead, ensure that the code you have written to compute the cost is correct. Just run the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta_testcase=np.zeros((5,1))\n",
    "cost_verify= compute_cost(Xs,y,beta_testcase,m)\n",
    "print(cost_verify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your output should be equal to 0.69314718056. If it's equal to this, then move ahead. Else, re-check your code and re- verify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent Algorithm\n",
    "\n",
    "Write the code to perform Gradient Descent in the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(Xs,y,learning_rate,beta,m,num_iters):\n",
    "    # In place of None, write the updated value of beta vector.\n",
    "    for i in range(num_iters):\n",
    "        # First calculate yhat and use this to find derivative of beta \n",
    "        yhat=None\n",
    "        temp = None\n",
    "        beta = temp\n",
    "       \n",
    "        \n",
    "        if(i%100==0):\n",
    "            # In place of None, call the cost you just coded above\n",
    "            cost= compute_cost(X,y,beta,m)\n",
    "            print(\"Cost\")\n",
    "            print(cost)\n",
    "             \n",
    "            \n",
    "    return beta      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving ahead, ensure that your code to update beta is correct. Run the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this code cell\n",
    "beta_testcase=np.zeros((5,1))\n",
    "g=gradient_descent(Xs,y,0.9,beta_testcase,m,10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of last cost should be -0.637440283634. If it's not equal, re-check your code in the gradient_ascent(..) function and re-verify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating the above functions into a single function logistic_reg_model_gda: This function uses gradient descent algorithm to minimize the cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_reg_model_gda(Xs,y,m,learning_rate,num_iters):\n",
    "    #initialize the values of parameter vector beta. It should be a column vector of zeros of dimension(m,1)\n",
    "    beta = None\n",
    "    \n",
    "    #calculate the initial cost by calling the function you coded above.\n",
    "    initial_cost = None\n",
    "    print(\"Initial Cost\")\n",
    "    print(initial_cost)\n",
    "    \n",
    "    #calculate the optimized value of gradients by calling the gradient_descent function coded above\n",
    "    \n",
    "    beta = None\n",
    "    \n",
    "    #Calculate the cost with the optimized value of beta by calling the cost function.\n",
    "    \n",
    "    final_cost = None\n",
    "    print(\"Final Cost\")\n",
    "    print(final_cost)\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when you have coded logistic_reg_model_gda function, you can call this function to find the optimized values of parameters beta. Before calling the function, set the values of learning_rate and num_iters. You may have to call this function several number of times with different values of num_iters and learning_rate to find the optimal values of parameters beta. For some values of learning_rate, it may give an error as the values of parameters may reach a very high value(infinity) due to overshooting as discussed in the class. For your help, you may use the value of learning_rate around 0.9 or 1 and num_iters around 10000. We would recommend you to try even higher values of learning_rate so that you may see that cost will decrease due to overshooting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your code below\n",
    "learning_rate = None\n",
    "num_iters = None\n",
    "# In place of None, call the logistic_reg_model_gda.\n",
    "beta = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print the value of parameters beta and check.\n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assigment ends here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
