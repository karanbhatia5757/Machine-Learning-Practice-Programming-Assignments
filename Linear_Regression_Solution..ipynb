{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run this code cell using shift+enter before moving further\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names =[\n",
    "    'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', \n",
    "    'AGE',  'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'PRICE'\n",
    "]\n",
    "\n",
    "#Write your code below to save dataframe in the df variable below. In place of None, write the pandas command to read the csv file.\n",
    "df=pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data',\n",
    "                 header=None,delim_whitespace=True,names=names,na_values='?') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1=df[['PRICE','RM']]\n",
    "df2=df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=np.array(df2['RM'])\n",
    "y=np.array(df2['PRICE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=x.reshape(x.shape[0],1)\n",
    "y=y.reshape(y.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(x,y,'o')\n",
    "plt.xlabel(\"RM\")\n",
    "plt.ylabel('PRICE')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m=x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(x,y,beta0,beta1,m):\n",
    "    #Write your code in place of None. Cost can be calculated using a single line of code\n",
    "    cost=np.sum(((beta0 + x * beta1) - y) **2) / (2*m)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost=compute_cost(x,y,0,0,m)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(x,y,learning_rate,beta0,beta1,m,num_iters):\n",
    "    # In place of None, write the updated value of beta0 in temp0 and of beta1 in temp1\n",
    "    for i in range(num_iters):\n",
    "        temp0 =   beta0 - (learning_rate/m) * np.sum((beta0 +  x * beta1)- y)\n",
    "        temp1 =   beta1 - learning_rate * (np.sum(((beta0 + x * beta1)-y) * x) )/m\n",
    "        beta0 =temp0\n",
    "        beta1= temp1\n",
    "        \n",
    "        if(i%100==0):\n",
    "            cost= compute_cost(x,y,beta0,beta1,m)\n",
    "            print(\"Cost\")\n",
    "            print(cost)\n",
    "            print(\"Betas\")\n",
    "            print(beta0)\n",
    "            print(beta1)\n",
    "            \n",
    "            \n",
    "    return beta0,beta1       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=gradient_descent(x,y,0.04,0,0,m,10000)\n",
    "print(g[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(x,y,learning_rate,beta0,beta1,m,num_iters):\n",
    "\n",
    "    for j in range(num_iters):\n",
    "        \n",
    "        for i in range(0,m):\n",
    "        # Write updated value in beta0 in temp0 and of beta1 in temp1\n",
    "            temp0 = beta0 - (learning_rate) * ((beta0 +  x[i] * beta1)- y[i]) \n",
    "            temp1 = beta1 - learning_rate * (((beta0 + x[i] * beta1)-y[i]) * x[i])\n",
    "            beta0 =temp0\n",
    "            beta1 = temp1\n",
    "   \n",
    "\n",
    "        if(j%2000==0):\n",
    "            # Write your code below. In place of None, call the cost function you just coded above.\n",
    "            cost= compute_cost(x,y,beta0,beta1,m)\n",
    "            print(\"Cost\")\n",
    "            print(cost)\n",
    "            print(\"Betas\")\n",
    "            print(beta0)\n",
    "            print(beta1)\n",
    "            \n",
    "            \n",
    "            \n",
    "    return beta0,beta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g=stochastic_gradient_descent(x,y,0.0048,0,0,m,10000)\n",
    "print(g[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_reg_model_gda(x,y,m,learning_rate,num_iters):\n",
    "    #initialize the values of parameters beta0 and beta1 both to 0\n",
    "    beta0=0\n",
    "    beta1=0\n",
    "    \n",
    "    #calculate the initial cost by calling the function you just coded above\n",
    "   \n",
    "    initial_cost=compute_cost(x,y,beta0,beta1,m)\n",
    "    print(\"Initial Cost\")\n",
    "    print(initial_cost)\n",
    "    \n",
    "\n",
    "    \n",
    "    #calculate the optimized value of beta0 and beta1 by calling the gradient_descent function coded above\n",
    "    \n",
    "    beta0,beta1= gradient_descent(x,y,learning_rate,beta0,beta1,m,num_iters)\n",
    "    \n",
    "    #Calculate the cost with the optimized value of beta0 and beta1 by calling the cost function.\n",
    "    \n",
    "    final_cost=compute_cost(x,y,beta0,beta1,m)\n",
    "    print(\"Final cost\")\n",
    "    print(final_cost)\n",
    "    return beta0,beta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.048\n",
    "num_iters=10000\n",
    "beta0,beta1=linear_reg_model_gda(x,y,m,learning_rate,num_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(beta0)\n",
    "print(beta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_reg_model_sgda(x,y,m,learning_rate,num_iters):\n",
    "    \n",
    "     #initialize the values of parameters beta0 and beta1 both to 0\n",
    "    beta0=0\n",
    "    beta1=0\n",
    "    \n",
    "    #calculate the initial cost by calling the function cost you just coded above\n",
    "    print(\"Initial Cost\")\n",
    "    initial_cost=compute_cost(x,y,beta0,beta1,m)\n",
    "    print(initial_cost)\n",
    "    \n",
    "    #calculate the optimized value of beta0 and beta1 by calling the stochastic_gradient_descent function coded above\n",
    "    \n",
    "    beta0,beta1= stochastic_gradient_descent(x,y,learning_rate,beta0,beta1,m,num_iters)\n",
    "    \n",
    "    #Calculate the cost with the optimized value of beta0 and beta1 by calling the cost function.\n",
    "    \n",
    "    final_cost=compute_cost(x,y,beta0,beta1,m)\n",
    "    print(\"Final_cost\")\n",
    "    print(final_cost)\n",
    "    return beta0,beta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.000048\n",
    "num_iters=10000\n",
    "beta0,beta1=linear_reg_model_sgda(x,y,m,learning_rate,num_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(x,beta0,beta1):\n",
    "    predicted_y=beta0 + beta1 * x\n",
    "    \n",
    "    return predicted_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict= predict(8,beta0,beta1)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normal Equation Method\n",
    "a=np.ones((m,1))\n",
    "X=np.hstack((a,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q=np.linalg.inv((np.dot(X.T, X )))\n",
    "w=np.dot(X.T,y)\n",
    "beta_vec=np.dot(q,w)\n",
    "beta0=beta_vec[0][0]\n",
    "beta1=beta_vec[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(beta0)\n",
    "print(beta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Beta0 is \" + str(beta0))\n",
    "print(\"Beta1 is \" + str(beta1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
