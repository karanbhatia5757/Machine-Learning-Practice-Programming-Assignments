{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Multiple Linear Regression on Robot Calibration using Gradient Descent And Stochastic Gradient Descent Algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will be implementing Multiple Linear Regression Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run this code cell using shift+enter before moving further\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below code cell. Use pd.read_csv('File url ', header=None,.... ) with the value of header=None,delim_whitespace=True,names=names,na_values='?' as attributes. Use the same file i.e. exp1.csv and ensure that file is in the present working directory. Otherwise you will have to give full path of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# After completing the code in this code cell, run this code cell before moving further.\n",
    "names =[\n",
    "    't',                                  # Time (secs)\n",
    "    'q1', 'q2', 'q3',                     # Joint angle   (rads)\n",
    "    'dq1', 'dq2', 'dq3',                  # Joint velocity (rads/sec)\n",
    "    'I1', 'I2', 'I3',                     # Motor current (A)\n",
    "    'eps21', 'eps22', 'eps31', 'eps32',   # Strain gauge measurements ($\\mu$m /m )\n",
    "    'ddq1', 'ddq2', 'ddq3'                # Joint accelerations (rad/sec^2)\n",
    "]\n",
    "\n",
    "# In place of None, write the pandas command.\n",
    "df=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the value of I2 column in ytrain numpy vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#After completing the code, run this cell.\n",
    "ytrain=None\n",
    "# We have already written the code below to reshape ytrain as rank 2 matrix i.e. of  dimension(m,1)\n",
    "ytrain=ytrain.reshape((ytrain.shape[0],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the value in Xtrain: A matrix of the data with the columns:  ['q2','dq2','eps21', 'eps22', 'eps31', 'eps32','ddq2']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# After completing the code, run the code cell.\n",
    "df1 = df[['q2','dq2','eps21', 'eps22', 'eps31', 'eps32','ddq2']]\n",
    "Xtrain=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving further, you should know that you would be using vectorization as done in the lecture. Calculate the total number of training examples in the variable m using ytrain.shape[0] command. Also, append a column of ones of dimension(m,1) as the first column of Xtrain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# After completing the code in this code cell, run this code cell before moving further. \n",
    "m=None\n",
    "# Store a column vector of ones in the variable a below using np.ones command. \n",
    "a=None\n",
    "# Append this as the first column of Xtrain using np.hstack command and save it in X_train.\n",
    "X_train=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here onwards, use X_train as your training set for values of input/independent variable and y_train as training set of output or dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the cost: Write the code to compute the cost inside the function. Do not change the function name or function parameters. Here, beta is vector having (nx+1) parameters  i.e. from beta0 to beta_n where nx is the number of features or independent variable as discussed in the lecture. In this assignment, beta will be a vector of size 8 i.e. 7+1. Beta will be a column vector of dimension (nx+1,1). Use the cost function as discussed in the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(X_train,y_train,beta,m):\n",
    "    #Write your code in place of None. Cost can be calculated using a single line of code\n",
    "    cost=None\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving ahead, ensure that the code you have written to compute the cost is correct. Just run the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta_testcase=np.zeros((8,1))\n",
    "cost_verify= compute_cost(X_train,y_train,beta_testcase,m)\n",
    "print(cost_verify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your output should be equal to 0.0687518922954. If it's equal to this, then move ahead. Else, re-check your code and re- verify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "Write the code to perform Gradient Descent in the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X_train,y_train,learning_rate,beta,m,num_iters):\n",
    "    # In place of None, write the updated value of beta vector.\n",
    "    for i in range(num_iters):\n",
    "        temp = None\n",
    "        beta = temp\n",
    "       \n",
    "        \n",
    "        if(i%100==0):\n",
    "            # In place of None, call the cost you just coded above\n",
    "            cost= None\n",
    "            print(\"Cost\")\n",
    "            print(cost)\n",
    "             \n",
    "            \n",
    "    return beta      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving ahead, ensure that your code to update beta is correct. Run the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta_testcase=np.zeros((8,1))\n",
    "g=gradient_descent(X_train,y_train,0.000022,beta_testcase,m,100000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of last cost should be 0.00701624120598. If it's not equal, re-check your code in the gradient_descent(..) function and re-verify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent\n",
    "Write the code to perform stochastic gradient descent. Remember, every update in sgda uses examples one by one. Be extra careful with the dimensions!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X_train,y_train,learning_rate,beta,m,num_iters):\n",
    "\n",
    "    for j in range(num_iters):\n",
    "    \n",
    "        for i in range(0,m):\n",
    "        # Write updated value of beta vector in place of None\n",
    "            temp = None \n",
    "        \n",
    "            beta = temp\n",
    "   \n",
    "\n",
    "        if(j%2000==0):\n",
    "            cost= None\n",
    "            print(\"Cost\")\n",
    "            print(cost)\n",
    "            \n",
    "            \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving ahead, ensure that your code to update beta is correct. Just run the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta_testcase=np.zeros((8,1))\n",
    "testcasext=np.arange(0,8)\n",
    "testcasex=testcasext.reshape(1,8)\n",
    "testcaseyt=np.array(([1]))\n",
    "testcasey=testcaseyt.reshape(1,1)\n",
    "g=stochastic_gradient_descent(testcasex,testcasey,0.0096,beta_testcase,1,10)\n",
    "yhat=np.dot(testcasex , g.reshape((8,1)))\n",
    "print(yhat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of last cost should be [[ 0.99997679]]. If it's not equal, re-check your code in the stochastic_gradient_descent(..) function and re-verify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating the above functions into a single function multiple_linear_reg_model_gda: This function uses gradient descent algorithm to minimize the cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiple_linear_reg_model_gda(X_train,y_train,m,learning_rate,num_iters):\n",
    "    #initialize the values of parameter vector beta. It should be a column vector of zeros of dimension(m,1)\n",
    "    beta= None\n",
    "    \n",
    "    #calculate the initial cost by calling the function you coded above.\n",
    "    initial_cost=None\n",
    "    print(\"Initial Cost\")\n",
    "    print(initial_cost)\n",
    "    \n",
    "    #calculate the optimized value of gradients by calling the gradient_descent function coded above\n",
    "    \n",
    "    beta= None\n",
    "    \n",
    "    #Calculate the cost with the optimized value of beta by calling the cost function.\n",
    "    \n",
    "    final_cost=None\n",
    "    print(\"Final Cost\")\n",
    "    print(final_cost)\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when you have coded multiple_linear_reg_model_gda function, you can call this function to find the optimized values of parameters beta. Before calling the function, set the values of learning_rate and num_iters. You may have to call this function several number of times with different values of num_iters and learning_rate to find the optimal values of parameters beta. For some values of learning_rate, it may give an error as the values of parameters may reach a very high value(infinity) due to overshooting as discussed in the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your code below\n",
    "learning_rate=None\n",
    "num_iters=None\n",
    "# In place of None, call the multiple_linear_reg_model_gda( ) function you coded above .\n",
    "beta=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again integrating the functions into a different function multiple_linear_reg_model_sgda(). This function uses stochastic gradient descent to minimize the cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiple_linear_reg_model_sgda(X_train,y_train,m,learning_rate,num_iters):\n",
    "    #initialize the values of parameter vector beta. It should be a column vector of zeros of dimension(m,1)\n",
    "    beta= None\n",
    "    \n",
    "    #calculate the initial cost by calling the function you coded above.\n",
    "    initial_cost=None\n",
    "    print(\"Initial Cost\")\n",
    "    print(initial_cost)\n",
    "    \n",
    "    #calculate the optimized value of gradients by calling the stochastic_gradient_descent function coded above\n",
    "    \n",
    "    beta= None\n",
    "    \n",
    "    #Calculate the cost with the optimized value of beta by calling the cost function.\n",
    "    \n",
    "    final_cost=None\n",
    "    print(\"Final Cost\")\n",
    "    print(final_cost)\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when you have coded multiple_linear_reg_model_sgda function, you can call this function to find the optimized values of parameters beta. Before calling the function, set the values of learning_rate and num_iters. You may have to call this function several number of times with different values of num_iters and learning_rate to find the optimal values of parameters beta. For some values of learning_rate, it may give an error as the values of parameters may reach a very high value(infinity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your code below\n",
    "learning_rate=None\n",
    "num_iters=None\n",
    "# In place of None, call the function multiple_linear_reg_model_sgda.\n",
    "beta=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use any of the above two functions to train your linear regression model to find the optimal values of the parameters. Once you have the optimal values of parameters, you can use them to predict new value of y using new value of x(features). Code the function below to predict y using x and beta. Both x(1,8) and beta( 8,1) are vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your code below\n",
    "def predict(x,beta):\n",
    "    predicted_y=None\n",
    "    \n",
    "    return predicted_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, to evaluate your model, you can use the test set given in a separate file exp2.csv. We are not including this part in this assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Equation Method\n",
    "\n",
    "Now, we will be writing code to find the values of parameters beta for our multiple linear regression model. This can also be used to cross-check the optimal values of beta we just found above using any one of the above two methods. These values should be same(or nearly same). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we don't need to append a column of ones to X_train matrixa as we did in programming_assignment_1b, because we have already done this at the starting of gradient descent algorithm. We will use the same X_train and y_train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of writing the code for normal equation in one line, you can break this into 3 parts: First calculate q=inverse of (dot of (X.T,X)) (these are pseudo commands, use original numpy commands to calculate q). Then w= dot of ( X.T , y) and then beta= dot of (q,w). Here, beta is a vector of dimension (nx+1,1) or (8,1) in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write the code below\n",
    "q = None\n",
    "w = None\n",
    "beta = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compare the values of parameters beta from this method and the values you got from the previous methods ( GDA or SGDA). They should be same or approximately same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment ends here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
