{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run this code cell using shift+enter before moving further\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import linear_model, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data_Cortex_Nuclear.csv',na_values='?' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1=df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yraw=np.array(df1['Genotype'])\n",
    "a,y=np.unique(yraw, return_inverse=\"True\")\n",
    "y=y.reshape((y.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xnames =['H3AcK18_N','EGR1_N','H3MeK4_N','CaNA_N'] \n",
    "Xs=np.array(df1[xnames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xs=preprocessing.scale(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving further, you should know that you would be using vectorization as done in the lecture. Calculate the total number of training examples in the variable m using y.shape[0] command. Also, append a column of ones of dimension(m,1) as the first column of Xs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m=y.shape[0]\n",
    "a=np.ones((m,1))\n",
    "Xs=np.hstack((a,Xs))\n",
    "Xs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid Function\n",
    "This function takes input as vector and outputs sigmoid of every element of that vector. Here v is vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "def sigmoid(v):\n",
    "    a=np.exp(-v)\n",
    "    b=1+a\n",
    "    yhat=1/b\n",
    "    \n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost\n",
    "Compute the cost: Write the code to compute the cost inside the function. Do not change the function name or function parameters. Here, beta is vector having (nx+1) parameters i.e. from beta0 to beta_n where nx is the number of features or independent variable as discussed in the lecture. In this assignment, beta will be a vector of size 5 i.e. 4+1. Beta will be a column vector of dimension (nx+1,1). Use the cost function as discussed in the class. You can use the above sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(Xs,y,beta,m):\n",
    "    #Write your code in place of None. Cost can be calculated using a single line of code\n",
    "    yhat= sigmoid(np.dot(Xs,beta))\n",
    "   \n",
    "    cost= (np.sum(np.multiply(y,np.log(yhat))) + np.sum(np.multiply(1-y,np.log(1-yhat))))/m \n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta_testcase=np.zeros((5,1))\n",
    "cost_verify= compute_cost(Xs,y,beta_testcase,m)\n",
    "print(cost_verify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Ascent\n",
    "\n",
    "Write the code to perform Gradient Descent in the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_ascent(Xs,y,learning_rate,beta,m,num_iters):\n",
    "    # In place of None, write the updated value of beta vector.\n",
    "    for i in range(num_iters):\n",
    "        yhat=sigmoid(np.dot(Xs,beta))\n",
    "        temp = beta + (learning_rate/m) * -(np.dot(Xs.transpose(), yhat-y))\n",
    "        beta = temp\n",
    "       \n",
    "        \n",
    "        if(i%100==0):\n",
    "            # In place of None, call the cost you just coded above\n",
    "            cost= compute_cost(Xs,y,beta,m)\n",
    "            print(\"Cost\")\n",
    "            print(cost)\n",
    "             \n",
    "            \n",
    "    return beta      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta_testcase=np.zeros((5,1))\n",
    "g=gradient_ascent(Xs,y,0.9,beta_testcase,m,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_reg_model_gda(Xs,y,m,learning_rate,num_iters):\n",
    "    #initialize the values of parameter vector beta. It should be a column vector of zeros of dimension(m,1)\n",
    "    beta= np.zeros((Xs.shape[1],1))\n",
    "    \n",
    "    #calculate the initial cost by calling the function you coded above.\n",
    "    initial_cost=compute_cost(Xs,y,beta,m)\n",
    "    print(\"Initial Cost\")\n",
    "    print(initial_cost)\n",
    "    \n",
    "    #calculate the optimized value of gradients by calling the gradient_ascent function coded above\n",
    "    \n",
    "    beta= gradient_ascent(Xs,y,learning_rate,beta,m,num_iters)\n",
    "    \n",
    "    #Calculate the cost with the optimized value of beta by calling the cost function.\n",
    "    \n",
    "    final_cost=compute_cost(Xs,y,beta,m)\n",
    "    print(\"Final Cost\")\n",
    "    print(final_cost)\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when you have coded logistic_reg_model_gda function, you can call this function to find the optimized values of parameters beta. Before calling the function, set the values of learning_rate and num_iters. You may have to call this function several number of times with different values of num_iters and learning_rate to find the optimal values of parameters beta. For some values of learning_rate, it may give an error as the values of parameters may reach a very high value(infinity) due to overshooting as discussed in the class. For your help, you may use the value of learning_rate around 0.9 or 1 and num_iters around 10000. We would recommend you to try even higher values of learning_rate so that you may see that cost will rise due to overshooting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your code below\n",
    "learning_rate=0.9\n",
    "num_iters=10000\n",
    "# In place of None, call the multiple_linear_reg_model_gda.\n",
    "beta=logistic_reg_model_gda(Xs,y,m,learning_rate,num_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
